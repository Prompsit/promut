devices:
    - 0

num-devices: 1

log: /work/tudor/bismut/training/log.txt

after: 4e
seed: 42
mini-batch-fit: True
workspace: 8000
shuffle-in-ram: true # speed up shuffling, may eat all the ram when using very big training files

early-stopping: 5
exponential-smoothing: 0.0001
keep-best: True
valid-freq: 1000
valid-mini-batch: 20
save-freq: 300
overwrite: True
disp-freq: 20
#disp-first: 10
quiet-translation: true

valid-metrics:
    - ce-mean-words
    - perplexity
    - bleu-detok
    - bleu

beam-size: 6
normalize: 1
max-length: 200

cost-type: ce-mean-words
type: transformer
enc-depth: 6
dec-depth: 6
dim-emb: 512
transformer-heads: 8
transformer-dim-ffn: 2048
transformer-ffn-depth: 2
transformer-ffn-activation: swish
transformer-decoder-autoreg: self-attention

transformer-dropout: 0.1
label-smoothing: 0.1

layer-normalization: True
tied-embeddings-all: True

learn-rate: 0.0003
lr-warmup: 1000
lr-decay-inv-sqrt: 16000
lr-report: True
optimizer-params:
    - 0.9
    - 0.98
    - 1e-09
clip-norm: 0 # disable clipping
sync-sgd: true
optimizer-delay: 2
